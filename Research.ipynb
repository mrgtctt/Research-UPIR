{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrgtctt/Research-UPIR/blob/main/Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TransNN Research\n",
        "We're going to implement TransNN model and test it on various datasets. But first we're going to define some terms and some templates.\n"
      ],
      "metadata": {
        "id": "GpnY9ZLwhbeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dataset, c'est des données pour lesquelles on spécifie le type de donnée à chaque fois.\n",
        "Label c'est quoi ?\n",
        "Label c'est ce que tu veux prédire. C'est la valeur que tu aimerais pouvoir prédire.\n",
        "Le Label c'est une colonne dans le dataset. Chaque colonne du dataset correspond à un type de donnée. La première ligne décrit c'est quel type de donnée, et le reste des lignes correspondent aux données (record).\n",
        "https://docs.google.com/spreadsheets/d/1pcJQlx05s3wVwaegmymA1OWowkxV5X1Pr8PCo-XYUCM/edit?usp=sharing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "seZkkeyxjfzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple example for model creation"
      ],
      "metadata": {
        "id": "Wc7KhQ0rvbsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diabetes prediction"
      ],
      "metadata": {
        "id": "twC9rSXYvlvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy_diabetes_model.py\n",
        "# ---------------------------------------\n",
        "# Toy example: predict \"diabetes\" vs \"no_diabetes\"\n",
        "# from age, weight (kg), height (cm).\n",
        "# EDUCATIONAL ONLY – NOT MEDICAL ADVICE.\n",
        "# ---------------------------------------\n",
        "\n",
        "# 1) Install scikit-learn if needed:\n",
        "#    pip install scikit-learn\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Fake training dataset\n",
        "#    [age, weight_kg, height_cm]  -> has_diabetes (0/1)\n",
        "# -----------------------------\n",
        "X = np.array([\n",
        "    [25, 60, 170],  # younger, normal weight\n",
        "    [30, 70, 175],\n",
        "    [35, 80, 180],\n",
        "    [40, 85, 172],\n",
        "    [45, 90, 168],\n",
        "    [50, 95, 165],\n",
        "    [55, 100, 170],\n",
        "    [60, 105, 165],\n",
        "    [65, 110, 160],\n",
        "    [70, 115, 158],\n",
        "])\n",
        "\n",
        "# Labels (completely made up)\n",
        "# 0 = no_diabetes, 1 = diabetes\n",
        "y_train = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]) #label d'entrainement.\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Train the model\n",
        "# -----------------------------\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Helper function\n",
        "# -----------------------------\n",
        "def predict_diabetes(age: int, weight_kg: float, height_cm: float) -> str:\n",
        "    \"\"\"\n",
        "    Return a label: 'diabetes' or 'no_diabetes' (toy example).\n",
        "    \"\"\"\n",
        "    features = np.array([[age, weight_kg, height_cm]])\n",
        "    prob_diabetes = model.predict_proba(features)[0, 1]  # probability of class 1\n",
        "\n",
        "    # Simple threshold\n",
        "    if prob_diabetes >= 0.5:\n",
        "        return f\"diabetes (probability: {prob_diabetes:.2f})\"\n",
        "    else:\n",
        "        return f\"no_diabetes (probability: {prob_diabetes:.2f})\"\n"
      ],
      "metadata": {
        "id": "G3fN9wQWh-Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Example person\n",
        "    age = 52\n",
        "    weight_kg = 92\n",
        "    height_cm = 170\n",
        "\n",
        "    result = predict_diabetes(age, weight_kg, height_cm)\n",
        "    print(f\"For age={age}, weight={weight_kg}kg, height={height_cm}cm:\")\n",
        "    print(\"Model prediction:\", result)\n"
      ],
      "metadata": {
        "id": "wr6EeTceh_RJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561754ca-ef83-4d55-e80b-db809968f79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For age=52, weight=92kg, height=170cm:\n",
            "Model prediction: diabetes (probability: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ce qui se passe réellement dans model = LogisticRegression() model.fit(X, y_train)\n"
      ],
      "metadata": {
        "id": "Iuskd8Rf6S2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durant L'entrainement, pour chaque donnée du dataset (chaque ligne), on va effectuer ceci en boucle\n",
        "```\n",
        "import dataset\n",
        "\n",
        "for x in dataset.values:\n",
        "\n",
        "  x = [age, weight, height] # ton entrée specifique\n",
        "  theta = [b, w1, w2, w3]   # bias + weights\n",
        "\n",
        "  y_pred = sigmoid(z)\n",
        "\n",
        "  z = b + w1*age + w2*weight + w3*height\n",
        "\n",
        "  sigmoid(z)= 1 / (1 + np.exp(-z)) # 1/(1+e^-z)\n",
        "\n",
        "  y_pred = sigmoid(z)\n",
        "\n",
        "  # y_true=\"pas_diabete\"\n",
        "  # if y_true==\"pas_diabete\":\n",
        "  #  y_true=1\n",
        "  # else:\n",
        "  #  y_true=0\n",
        "\n",
        "\n",
        "  error = y_pred - y_true\n",
        "\n",
        "  # Gradient descent update\n",
        "  theta[0] = theta[0] - learning_rate * error * 1        # bias\n",
        "  theta[1] = theta[1] - learning_rate * error * x[0]     # age\n",
        "  theta[2] = theta[2] - learning_rate * error * x[1]     # weight\n",
        "  theta[3] = theta[3] - learning_rate * error * x[2]     # height\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Après L'entrainement\n",
        "```\n",
        "\n",
        "x = [age, weight, height] # ton entrée specifique\n",
        "theta = [b, w1, w2, w3]   # bias + weights\n",
        "\n",
        "z = b + w1*age + w2*weight + w3*height\n",
        "\n",
        "sigmoid(z)= 1 / (1 + np.exp(-z)) # 1/(1+e^-z)\n",
        "\n",
        "y_pred = sigmoid(z)\n",
        "\n",
        "```\n",
        "Ok, donc y_pred est y_pred, mais on va l'interpréter.\n",
        "Par exemple: si on a 2 classes/catégories diabète ou pas diabète.\n",
        "Diabète=0 Pas_Diabète=1\n",
        "\n",
        "Et que j'obtiens 0.7. On va dire que il a pas le diabète parce que c'est plus proche de 1.\n",
        "\n",
        "Si j'avais 5000 classes (numerote de A0 a Z193).\n",
        "1/5000=0,0002\n",
        "Donc si je suis entre 0 et 0,0002, alors c'est la classse A0.\n",
        "Donc si je suis entre 0,0004 et 0,0006\n",
        "Je suis la classe A2"
      ],
      "metadata": {
        "id": "uSpCW6XgzR__"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EK3pEN_fzP30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TransNN Model Creation"
      ],
      "metadata": {
        "id": "IbKTjqLpvtFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summary: Virus Spread on Effective Transmission Networks**\n"
      ],
      "metadata": {
        "id": "M2jsd2MQEuNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "An **effective transmission link** $( i \\to j )$ means that person ( i ) can infect person ( j ).\n",
        "All such links form an **effective transmission network**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Probability of Infection**\n",
        "\n",
        "For each node ( i ):\n",
        "\n",
        "$[\n",
        "p_i(k) = \\Pr(\\text{Node } i \\text{ is infected at time } k),\n",
        "\\qquad i \\in [n].\n",
        "]$\n",
        "\n",
        "The **one-step prediction** of remaining *uninfected* is:\n",
        "\n",
        "$[\n",
        "1 - p_i(k+1)\n",
        "= \\prod_{j \\in N_i^{\\circ}} \\big(1 - p_j(k)\\big),\n",
        "]$\n",
        "\n",
        "where $( N_i^{\\circ} = { j : (i,j) \\in E } )$ **includes node ( i ) itself**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Shannon Information State**\n",
        "\n",
        "Define the transformed state:\n",
        "\n",
        "$[\n",
        "s_i(k) = -\\log(1 - p_i(k)) \\in [0, +\\infty].\n",
        "]$\n",
        "\n",
        "The transformation\n",
        "\n",
        "$[\n",
        "T(x) = -\\log(1 - x)\n",
        "]$\n",
        "\n",
        "is **monotone, bijective, and concave**.\n",
        "\n",
        "Under this transformation, the nonlinear infection dynamics become *linear*:\n",
        "\n",
        "$[\n",
        "s_i(k+1) = \\sum_{j \\in N_i^{\\circ}} s_j(k),\n",
        "\\qquad s_i(k) \\in [0, +\\infty].\n",
        "]$\n",
        "\n"
      ],
      "metadata": {
        "id": "MhskEafO7qo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "State transformation (page 9/31)"
      ],
      "metadata": {
        "id": "5kQAqYU78mCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sum(j) pour j allant de 1 à n.\n",
        "#n va jusqua 10\n",
        "sum(range(1,11))\n",
        "somme=0\n",
        "for j in range(1,11):\n",
        "  somme+=j*5\n",
        "somme\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pyvj6LG9I6a",
        "outputId": "3aa1393f-694d-48b9-921c-aa097b9b2203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "275"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "liste_avant_somme=np.array(range(1,11))\n",
        "liste_avant_somme"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs6R_H_l_D2n",
        "outputId": "ff19ca68-ae01-4907-8ab9-92c0259dc6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "liste_avant_somme=5*liste_avant_somme\n",
        "liste_avant_somme\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJK5QwSo_Tx2",
        "outputId": "1347d032-4532-45b4-db1b-70f6242a6f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "liste_avant_somme.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0Vq1jXX_ZA8",
        "outputId": "c5b39087-65be-4dd6-c117-4641ba493f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(275)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# TLogSigmoid activation Ψ(w, x)\n",
        "# Ψ(w, x) = - log(1 - w + w e^{-x}),   w ∈ [0, 1]\n",
        "# -----------------------------\n",
        "def psi_tlogsigmoid(w, x):\n",
        "    \"\"\"\n",
        "    TLogSigmoid activation Ψ(w, x).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    w : array-like\n",
        "        Edge weights w_ij in [0, 1]. Any shape.\n",
        "    x : array-like\n",
        "        Inputs x (here: s_j(k)). Shape must be broadcastable with w.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Ψ(w, x) with same broadcasted shape as w and x.\n",
        "    \"\"\"\n",
        "    return -np.log(1.0 - w + w * np.exp(-x))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Shannon information state:\n",
        "# s_i(k) = -log(1 - p_i(k))\n",
        "# p_i(k) = 1 - exp(-s_i(k))  (inverse)\n",
        "# -----------------------------\n",
        "def p_to_s(p, eps=1e-12):\n",
        "    \"\"\"p -> s via s = -log(1 - p).\"\"\"\n",
        "    p_clipped = np.clip(p, 0.0, 1.0 - eps)\n",
        "    return -np.log(1.0 - p_clipped)\n",
        "\n",
        "def s_to_p(s):\n",
        "    \"\"\"s -> p via p = 1 - exp(-s).\"\"\"\n",
        "    return 1.0 - np.exp(-s)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Spread process on probabilistic networks:\n",
        "#\n",
        "# 1 - p_i(k+1) = ∏_{j ∈ N_i°} (1 - w_ij p_j(k))^{a_ij}\n",
        "#\n",
        "# A = (a_ij) adjacency matrix (0 or 1)\n",
        "# W = (w_ij) edge transmission weights in [0, 1]\n",
        "# p(k) = vector of node infection probabilities\n",
        "# -----------------------------\n",
        "def spread_step_probabilistic(p, W, A):\n",
        "    \"\"\"\n",
        "    One step of the probabilistic spread model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    p : array, shape (n,)\n",
        "        Infection probabilities at time k.\n",
        "    W : array, shape (n, n)\n",
        "        Transmission weights w_ij in [0, 1].\n",
        "    A : array, shape (n, n)\n",
        "        Adjacency matrix (0/1), entries a_ij.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    p_next : array, shape (n,)\n",
        "        Infection probabilities at time k+1.\n",
        "    \"\"\"\n",
        "    # term_ij = (1 - w_ij * p_j(k))\n",
        "    term = 1.0 - W * p[np.newaxis, :]       # broadcast p over rows i\n",
        "\n",
        "    # If a_ij = 0, the factor is (·)^0 = 1  → we just force it to 1\n",
        "    term = np.where(A == 1, term, 1.0)\n",
        "\n",
        "    # product over j ∈ N_i°\n",
        "    prod = term.prod(axis=1)\n",
        "\n",
        "    # 1 - p_i(k+1) = prod_j term_ij\n",
        "    p_next = 1.0 - prod\n",
        "    return p_next\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Transmission Neural Network (TransNN):\n",
        "#\n",
        "# s_i(k+1) = Σ_{j=1}^n a_ij Ψ(w_ij, s_j(k))\n",
        "# -----------------------------\n",
        "def transnn_step(s, W, A):\n",
        "    \"\"\"\n",
        "    One TransNN layer / time-step.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s : array, shape (n,)\n",
        "        Shannon-information states s_j(k).\n",
        "    W : array, shape (n, n)\n",
        "        Transmission weights w_ij in [0, 1].\n",
        "    A : array, shape (n, n)\n",
        "        Adjacency matrix (0/1), entries a_ij.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    s_next : array, shape (n,)\n",
        "        Next states s_i(k+1).\n",
        "    \"\"\"\n",
        "    # Compute Ψ(w_ij, s_j(k)) for all i, j\n",
        "    # s is broadcasted across rows i\n",
        "    psi_vals = psi_tlogsigmoid(W, s[np.newaxis, :])\n",
        "\n",
        "    # s_i(k+1) = Σ_j a_ij Ψ(w_ij, s_j(k))\n",
        "    s_next = (A * psi_vals).sum(axis=1)\n",
        "    return s_next\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Small example of usage\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    n = 4\n",
        "    # Random adjacency and weights for demo\n",
        "    rng = np.random.default_rng(0)\n",
        "    A = (rng.random((n, n)) < 0.6).astype(float)   # a_ij ∈ {0,1}\n",
        "    np.fill_diagonal(A, 1.0)                       # include self in N_i°\n",
        "    W = rng.random((n, n))                         # w_ij ∈ [0,1]\n",
        "\n",
        "    # Initial infection probabilities\n",
        "    p = rng.random(n) * 0.2   # start with small infection probs\n",
        "    s = p_to_s(p)\n",
        "\n",
        "    for k in range(5):\n",
        "        print(f\"Step {k}:\")\n",
        "        print(\"  p =\", p)\n",
        "        print(\"  s =\", s)\n",
        "\n",
        "        # Spread model update in probability space\n",
        "        p = spread_step_probabilistic(p, W, A)\n",
        "        # Corresponding Shannon state\n",
        "        s = p_to_s(p)\n",
        "\n",
        "        # Or directly use TransNN update in s-space:\n",
        "        # s = transnn_step(s, W, A)\n",
        "        # p = s_to_p(s)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjlTu3IJAVtA",
        "outputId": "28e20c89-38f6-4833-dbfd-f8f4034c2e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0:\n",
            "  p = [0.0270193  0.14429767 0.10507086 0.06204838]\n",
            "  s = [0.02739103 0.15583271 0.11101074 0.0640569 ]\n",
            "Step 1:\n",
            "  p = [0.15085572 0.01793379 0.17323947 0.11572668]\n",
            "  s = [0.16352616 0.01809655 0.19024019 0.12298908]\n",
            "Step 2:\n",
            "  p = [0.22332958 0.00222887 0.33473516 0.05614875]\n",
            "  s = [0.25273919 0.00223136 0.40757005 0.0577867 ]\n",
            "Step 3:\n",
            "  p = [2.91849509e-01 2.77011242e-04 4.57006383e-01 2.32555810e-02]\n",
            "  s = [3.45098650e-01 2.77049617e-04 6.10657715e-01 2.35302589e-02]\n",
            "Step 4:\n",
            "  p = [3.60825466e-01 3.44278648e-05 5.63666910e-01 9.22314850e-03]\n",
            "  s = [4.47577725e-01 3.44284575e-05 8.29349359e-01 9.26594509e-03]\n"
          ]
        }
      ]
    }
  ]
}